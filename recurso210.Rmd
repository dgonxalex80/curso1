---
title: <span style="color:#004080">**Análisis de Conglomerado**</span>
subtitle: "Estadística avanzada"
author: "Pontificia Universidad Javeriana Cali"
date: "2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Colores - paleta de azules
c1="#001A33"
c2="#003366"
c3="#004080"
c4="#1A8CFF"
c5="#4DA6FF"
c6="#80BFFF"
c7="#B3D9FF"

# <span style="color:#001A33"> 

## <span style="color:#003366">  

### <span style="color:#004080">
### <span style="color:#1A8CFF">
### <span style="color:#4DA6FF">
### <span style="color:#80BFFF">
### <span style="color:#B3D9FF">

```

<br/><br/>

El **análisis de conglomerados**, también conocido como **análisis de clústeres**, es una técnica de aprendizaje automático no supervisado que se utiliza para agrupar un conjunto de objetos de manera que los objetos en el mismo grupo (o clúster) sean más similares entre sí que con los de otros grupos. Su principal objetivo es identificar estructuras intrínsecas en los datos, agrupar datos similares y descubrir patrones y correlaciones subyacentes.

Esta técnica es ampliamente aplicable en diversas áreas como la segmentación de mercado, la organización de computadoras y redes, la clasificación de genes y muestras en informática biológica, y la reducción de la dimensionalidad en procesamiento de señales e imágenes. En el campo del marketing, por ejemplo, el análisis de clústeres puede ayudar a segmentar a los clientes en grupos según preferencias de compra, demografía y comportamiento, lo que permite a las empresas diseñar estrategias de marketing más efectivas y personalizadas.

<br/><br/>

El proceso de análisis de conglomerados incluye varios pasos clave:

<br/><br/>

1. **Selección de variables**: 

Elegir las variables relevantes que se utilizarán para medir la similitud entre los objetos.

<br/><br/>

2. **Determinación de la métrica de similitud**: 

Definir un criterio para medir la similitud o la distancia entre los objetos. Las medidas comunes incluyen la distancia euclidiana, la distancia de Manhattan y la similitud del coseno.

<br/><br/>

3. **Selección del método de conglomerado**: 

Elegir un algoritmo para realizar la agrupación. Los métodos comunes incluyen K-means, agrupamiento jerárquico, DBSCAN, y métodos basados en modelos como la mezcla de gaussianas.

<br/><br/>

4. **Validación de los clústeres**: 

Evaluar la calidad y la pertinencia de los clústeres generados. Esto puede incluir métodos como el análisis de silueta, el índice Davies-Bouldin, o el codo de Jambú.

<br/><br/>

5. **Interpretación y aplicación de los resultados**: 

Interpretar los clústeres en el contexto del problema específico y aplicar los conocimientos adquiridos para tomar decisiones o mejorar procesos.

El éxito del análisis de conglomerados depende en gran medida de la elección adecuada de las variables, la métrica de similitud y el algoritmo de agrupamiento, así como de la correcta interpretación de los grupos resultantes. Aunque poderosa, esta técnica también presenta desafíos, como la sensibilidad a las escalas de las variables y la dificultad de determinar el número óptimo de clústeres. Por tanto, una comprensión profunda del dominio del problema y un enfoque cuidadoso en la preparación y análisis de los datos son cruciales para obtener resultados significativos y aplicables.

<br/><br/>

### **Ejemplo**


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Cargar las librerías necesarias
library(tidyverse)  # para manipulación de datos y gráficos
library(cluster)    # para análisis de clústeres
library(factoextra) # para visualizaciones de clústeres

# Crear un dataframe simulado de clientes de una entidad financiera
set.seed(123)  # Para reproducibilidad
data <- data.frame(
  edad = rnorm(100, mean = 50, sd = 10),
  ingresos = rnorm(100, mean = 50000, sd = 15000),
  saldo_promedio = rnorm(100, mean = 2000, sd = 800),
  productos_contratados = sample(1:5, 100, replace = TRUE),
  frecuencia_uso_digital = sample(1:100, 100),
  calificacion_credito = sample(300:850, 100, replace = TRUE)
)

# Normalizar los datos
data_scaled <- scale(data)

# Ejecutar k-means clustering
set.seed(123)
kmeans_result <- kmeans(data_scaled, centers = 4, nstart = 25)

# Añadir los resultados del clúster al dataframe original
data$cluster <- as.factor(kmeans_result$cluster)

# # Visualización de los clústeres usando PCA
# pca <- prcomp(data_scaled)
# fviz_pca_ind(pca,
#              col.ind = data$cluster, # Color by cluster
#              palette = c("#2E9FDF", "#E76BF3", "#FC913A", "#58C9B9"),
#              addEllipses = TRUE, # Añadir elipses de confianza
#              legend.title = "Cluster")
# 
# # Visualizar las diferencias en las variables originales por clúster
# data %>% # # Visualización de los clústeres usando PCA
# pca <- prcomp(data_scaled)
# fviz_pca_ind(pca,
#              col.ind = data$cluster, # Color by cluster
#              palette = c("#2E9FDF", "#E76BF3", "#FC913A", "#58C9B9"),
#              addEllipses = TRUE, # Añadir elipses de confianza
#              legend.title = "Cluster")
# 
# # Visualizar las diferencias en las variables originales por clúster
# data %>% 
#   gather(attribute, value, -cluster) %>%
#   ggplot(aes(x = cluster, y = value, fill = cluster)) +
#   geom_boxplot() +
#   facet_wrap(~attribute, scales = 'free') +
#   theme_minimal() +
#   labs(title = "Distribución de Atributos por Clúster",
#        x = "Clúster",
#        y = "Valor",
#        fill = "Clúster")
#   gather(attribute, value, -cluster) %>%
#   ggplot(aes(x = cluster, y = value, fill = cluster)) +
#   geom_boxplot() +
#   facet_wrap(~attribute, scales = 'free') +
#   theme_minimal() +
#   labs(title = "Distribución de Atributos por Clúster",
#        x = "Clúster",
#        y = "Valor",
#        fill = "Clúster")

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Cargar las librerías necesarias
library(tidyverse)
library(cluster)    # para análisis de clústeres
library(factoextra) # para visualizaciones mejoradas

# Suponiendo que 'data_scaled' ya está definido como tus datos normalizados

# Ejecutar el agrupamiento jerárquico
dist_matrix <- dist(data_scaled)  # Calcular la matriz de distancias
hc <- hclust(dist_matrix, method = "ward.D2")  # Realizar el agrupamiento jerárquico

# Crear un dendrograma
# plot(hc, labels = FALSE, hang = -1)  # 'labels = FALSE' para evitar un gráfico sobrecargado
# rect.hclust(hc, k = 4, border = 2)  # Añadir rectángulos para 4 clústeres

# Usando factoextra para un mejor dendrograma
fviz_dend(hc, k = 4, # Número de clústeres a cortar
          cex = 0.5, # Tamaño de texto
          k_colors = c("#2E9FDF", "#E76BF3", "#FC913A", "#58C9B9"), # Colores de clústeres
          rect = TRUE, # Añadir rectángulos para identificar clústeres
          main = "Dendrograma del Agrupamiento Jerárquico") # Título del gráfico

```

<br/><br/>


El resultado del análisis es una clasificación de los clientes en cuatro grupos más homogeneos o parecidos. Esta clasificación captada en una nueva variable, permite comparar estos grupor por las diferentes variables. Es así como podríamos decir :

* El grupo 4 presenta la menor calificación de crédito, menor edad promedio y el mayor saldo promedio
* El Grupo 2 presenta la menor frecuencia de uso digital
* El grupo 3 presenta el menor número de productos contratados y menor saldo promedio
* El grupo 1 presenta el mayor número de productos contratados, la mayor frecuencia de uso digital








```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Añadir los resultados del clúster al dataframe original
data$cluster <- as.factor(kmeans_result$cluster)

# Visualización de los clústeres usando PCA
pca <- prcomp(data_scaled)
# fviz_pca_ind(pca,
#              col.ind = data$cluster, # Color by cluster
#              palette = c("#2E9FDF", "#E76BF3", "#FC913A", "#58C9B9"),
#              addEllipses = TRUE, # Añadir elipses de confianza
#              legend.title = "Cluster")

# Visualizar las diferencias en las variables originales por clúster
data %>% 
  gather(attribute, value, -cluster) %>%
  ggplot(aes(x = cluster, y = value, fill = cluster)) +
  geom_boxplot() +
  facet_wrap(~attribute, scales = 'free') +
  theme_minimal() +
  labs(title = "Distribuciones por Clúster",
       x = "Clúster",
       y = "Valor",
       fill = "Clúster")


```



